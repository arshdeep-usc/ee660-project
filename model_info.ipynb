{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a059a957-3a3d-49ef-a2a7-ddcfc7f0ebac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import gaussian_kde\n",
    "import datetime  \n",
    "\n",
    "# ---------- Residual Block ----------\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, h):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(h, h),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(h, h),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.net(x)\n",
    "\n",
    "# ---------- Generator ----------\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z=2, h=24, d=2, n_res=4):\n",
    "        super().__init__()\n",
    "        self.z_dim = z   \n",
    "\n",
    "        self.input = nn.Sequential(\n",
    "            nn.Linear(z, h),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        self.body = nn.Sequential(*[ResBlock(h) for _ in range(n_res)])\n",
    "        self.output = nn.Linear(h, d)\n",
    "\n",
    "    def forward(self, z):\n",
    "        h = self.input(z)\n",
    "        h = self.body(h)\n",
    "        return self.output(h)\n",
    "\n",
    "# ---------- Discriminator ----------\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, d=2, h=24, n_res=3):\n",
    "        super().__init__()\n",
    "        self.input = nn.Sequential(\n",
    "            nn.Linear(d, h),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        self.body = nn.Sequential(*[ResBlock(h) for _ in range(n_res)])\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Linear(h, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.input(x)\n",
    "        h = self.body(h)\n",
    "        return self.output(h)\n",
    "\n",
    "# ---------- Sampling function ----------\n",
    "@torch.no_grad()\n",
    "def sample_gan(G, n=2000, device=\"cpu\"):\n",
    "    G.eval()\n",
    "    z = torch.randn(n, G.z_dim, device=device)   \n",
    "    return G(z).cpu().numpy()\n",
    "\n",
    "# ---------- Training function ----------\n",
    "def models():    \n",
    "    # Initialize models\n",
    "    G = Generator(z=2, h=32, d=2, n_res=2).to(\"cpu\")\n",
    "    D = Discriminator(d=2, h=42, n_res=4).to(\"cpu\")\n",
    "\n",
    "    return G, D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99e6218c-50a5-4fbb-ac7f-c33352391cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import gaussian_kde\n",
    "import datetime  \n",
    "\n",
    "# ---------- Residual Block ----------\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, h):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(h, h),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(h, h),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return x + self.net(x)\n",
    "\n",
    "# ---------- VAE Model ----------\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, d=2, h=256, z=2, n_res=3):\n",
    "        super().__init__()\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(d, h),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(h),\n",
    "            *[ResBlock(h) for _ in range(n_res)],\n",
    "        )\n",
    "        self.fc_mu = nn.Linear(h, z)\n",
    "        self.fc_logvar = nn.Linear(h, z)\n",
    "\n",
    "        # Decoder\n",
    "        self.dec_in = nn.Sequential(\n",
    "            nn.Linear(z, h),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(h),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            *[ResBlock(h) for _ in range(n_res)],\n",
    "            nn.Linear(h, d)  # output is unbounded\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x)\n",
    "        mu = self.fc_mu(h)\n",
    "        logvar = self.fc_logvar(h)\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        z = mu + std * torch.randn_like(std)\n",
    "        h = self.dec_in(z)\n",
    "        return self.decoder(h), mu, logvar\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(self, n=2000, device=\"cpu\"):\n",
    "        z_ = torch.randn(n, self.fc_mu.out_features, device=device)\n",
    "        h = self.dec_in(z_)\n",
    "        return self.decoder(h).cpu().numpy()\n",
    "\n",
    "# ---------- Loss Function ----------\n",
    "def vae_loss(x, x_recon, mu, logvar, beta=0.2):\n",
    "    recon = nn.MSELoss(reduction=\"mean\")(x_recon, x)\n",
    "    kl = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return recon + beta * kl\n",
    "\n",
    "# ---------- Training Function ----------\n",
    "def model():\n",
    "    vae = VAE(d=2, h=128, z=24, n_res=3).to(\"cpu\")\n",
    "\n",
    "    return vae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "646c6a02-9518-42e7-bf24-5a8c721e4839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchviz in /Users/robin/miniconda3/lib/python3.12/site-packages (0.0.3)\n",
      "Requirement already satisfied: torch in /Users/robin/miniconda3/lib/python3.12/site-packages (from torchviz) (2.9.1)\n",
      "Requirement already satisfied: graphviz in /Users/robin/miniconda3/lib/python3.12/site-packages (from torchviz) (0.20.3)\n",
      "Requirement already satisfied: filelock in /Users/robin/miniconda3/lib/python3.12/site-packages (from torch->torchviz) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/robin/miniconda3/lib/python3.12/site-packages (from torch->torchviz) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /Users/robin/miniconda3/lib/python3.12/site-packages (from torch->torchviz) (72.1.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/robin/miniconda3/lib/python3.12/site-packages (from torch->torchviz) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /Users/robin/miniconda3/lib/python3.12/site-packages (from torch->torchviz) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/robin/miniconda3/lib/python3.12/site-packages (from torch->torchviz) (3.1.4)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /Users/robin/miniconda3/lib/python3.12/site-packages (from torch->torchviz) (2024.6.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/robin/miniconda3/lib/python3.12/site-packages (from sympy>=1.13.3->torch->torchviz) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/robin/miniconda3/lib/python3.12/site-packages (from jinja2->torch->torchviz) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "350bc6f2-3ad0-4041-92a1-d5f0999124e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved generator_graph.png and discriminator_graph.png\n",
      "Saved vae_graph.png\n"
     ]
    }
   ],
   "source": [
    "from torchviz import make_dot\n",
    "\n",
    "# --- Create models ---\n",
    "G = Generator(z=2, h=32, d=2, n_res=2)\n",
    "D = Discriminator(d=2, h=42, n_res=4)\n",
    "\n",
    "# --- Example input ---\n",
    "z = torch.randn(1, 2)      # latent input\n",
    "fake = G(z)                 # generator output\n",
    "\n",
    "# --- Graph for Generator ---\n",
    "gen_graph = make_dot(fake, params=dict(G.named_parameters()))\n",
    "gen_graph.render(\"generator_graph\", format=\"png\")\n",
    "\n",
    "# --- Graph for Discriminator ---\n",
    "disc_graph = make_dot(D(fake), params=dict(D.named_parameters()))\n",
    "disc_graph.render(\"discriminator_graph\", format=\"png\")\n",
    "\n",
    "print(\"Saved generator_graph.png and discriminator_graph.png\")\n",
    "\n",
    "from torchviz import make_dot\n",
    "\n",
    "vae = VAE(d=2, h=128, z=24, n_res=3)\n",
    "\n",
    "# --- Example input ---\n",
    "x = torch.randn(1, 2)\n",
    "\n",
    "# Full forward pass\n",
    "x_recon, mu, logvar = vae(x)\n",
    "\n",
    "# For VAE, visualize the whole forward output (reconstruction)\n",
    "vae_graph = make_dot(x_recon, params=dict(vae.named_parameters()))\n",
    "vae_graph.render(\"vae_graph\", format=\"png\")\n",
    "\n",
    "print(\"Saved vae_graph.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b034585d-6a1e-4bd7-97a5-1c07ac24567f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model summary → vae_summary_20251204_220244.png\n",
      "Saved model summary → generator_summary_20251204_220244.png\n",
      "Saved model summary → discriminator_summary_20251204_220244.png\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import sys\n",
    "import datetime\n",
    "from torchsummary import summary\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "\n",
    "def save_model_summary(model, input_size, filename=None):\n",
    "    \"\"\"\n",
    "    Saves the torchsummary(model) output as a PNG image.\n",
    "    Compatible with old versions of torchsummary.\n",
    "    \"\"\"\n",
    "\n",
    "    # ---------- Timestamp ----------\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    if filename is None:\n",
    "        filename = f\"model_summary_{timestamp}.png\"\n",
    "    else:\n",
    "        filename = filename.replace(\".png\", f\"_{timestamp}.png\")\n",
    "\n",
    "    # ---------- Capture stdout ----------\n",
    "    backup_stdout = sys.stdout\n",
    "    sys.stdout = io.StringIO()\n",
    "\n",
    "    try:\n",
    "        summary(model, input_size=input_size)\n",
    "        text = sys.stdout.getvalue()\n",
    "    finally:\n",
    "        sys.stdout = backup_stdout\n",
    "\n",
    "    lines = text.split(\"\\n\")\n",
    "\n",
    "    # ---------- Convert text → PNG ----------\n",
    "    font = ImageFont.load_default()\n",
    "    padding = 10\n",
    "    max_width = max(font.getbbox(line)[2] for line in lines)\n",
    "    line_height = font.getbbox(\"A\")[3] + 4\n",
    "    img_height = line_height * len(lines)\n",
    "\n",
    "    img = Image.new(\n",
    "        \"RGB\",\n",
    "        (max_width + 2 * padding, img_height + 2 * padding),\n",
    "        color=\"white\"\n",
    "    )\n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    y = padding\n",
    "    for line in lines:\n",
    "        draw.text((padding, y), line, fill=\"black\", font=font)\n",
    "        y += line_height\n",
    "\n",
    "    img.save(filename)\n",
    "    print(f\"Saved model summary → {filename}\")\n",
    "\n",
    "\n",
    "vae = VAE(d=2, h=128, z=24, n_res=3)\n",
    "save_model_summary(vae, input_size=(2,), filename=\"vae_summary.png\")\n",
    "\n",
    "G = Generator(z=2, h=32, d=2, n_res=2)\n",
    "save_model_summary(G, input_size=(2,), filename=\"generator_summary.png\")\n",
    "\n",
    "D = Discriminator(d=2, h=42, n_res=4)\n",
    "save_model_summary(D, input_size=(2,), filename=\"discriminator_summary.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "860b070a-4b36-47b2-a80c-5ffa03247d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import sys\n",
    "import datetime\n",
    "from torchsummary import summary\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "\n",
    "def get_summary_text(model, input_size):\n",
    "    \"\"\"Return string output of torchsummary(model). Compatible with old versions.\"\"\"\n",
    "    backup = sys.stdout\n",
    "    sys.stdout = io.StringIO()\n",
    "\n",
    "    try:\n",
    "        summary(model, input_size=input_size)\n",
    "        text = sys.stdout.getvalue()\n",
    "    finally:\n",
    "        sys.stdout = backup\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def save_gan_summary(generator, discriminator, input_size_G, input_size_D, filename=\"gan_summary.png\"):\n",
    "    \"\"\"\n",
    "    Saves Generator + Discriminator torchsummary outputs in ONE combined PNG image.\n",
    "    \"\"\"\n",
    "\n",
    "    # Timestamp for filename uniqueness\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = filename.replace(\".png\", f\"_{timestamp}.png\")\n",
    "\n",
    "    # ---------- Get summaries ----------\n",
    "    gen_text = get_summary_text(generator, input_size_G)\n",
    "    disc_text = get_summary_text(discriminator, input_size_D)\n",
    "\n",
    "    full_text = (\n",
    "        \"===== GENERATOR =====\\n\" + gen_text +\n",
    "        \"\\n\\n===== DISCRIMINATOR =====\\n\" + disc_text\n",
    "    )\n",
    "    lines = full_text.split(\"\\n\")\n",
    "\n",
    "    # ---------- Render summary as PNG ----------\n",
    "    font = ImageFont.load_default()\n",
    "    padding = 10\n",
    "    max_width = max(font.getbbox(line)[2] for line in lines)\n",
    "    line_height = font.getbbox(\"A\")[3] + 4\n",
    "    img_height = line_height * len(lines)\n",
    "\n",
    "    img = Image.new(\n",
    "        \"RGB\",\n",
    "        (max_width + 2 * padding, img_height + 2 * padding),\n",
    "        color=\"white\"\n",
    "    )\n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    y = padding\n",
    "    for line in lines:\n",
    "        draw.text((padding, y), line, fill=\"black\", font=font)\n",
    "        y += line_height\n",
    "\n",
    "    img.save(filename)\n",
    "    print(f\"Saved combined GAN summary → {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db1d957d-495a-47df-abe2-4150b4f1f8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved combined GAN summary → gan_summary_20251204_220429.png\n"
     ]
    }
   ],
   "source": [
    "G = Generator(z=2, h=32, d=2, n_res=2)\n",
    "D = Discriminator(d=2, h=42, n_res=4)\n",
    "\n",
    "save_gan_summary(\n",
    "    generator=G,\n",
    "    discriminator=D,\n",
    "    input_size_G=(2,),\n",
    "    input_size_D=(2,),\n",
    "    filename=\"gan_summary.png\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad53d51e-6333-4d24-bcc2-a87bb515f708",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
